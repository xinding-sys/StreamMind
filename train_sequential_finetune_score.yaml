description: videollm_mamba_stream_zero2_withoutcpu

target:
  service: sing
  name: msrresrchvc
  # name: msrresrchvc
  workspace_name: srgxws
  
environment:
  registry: singularitybase.azurecr.io
  image: base/job/pytorch/acpt-2.2.1-py3.10-cuda12.1:20240312T225111416
  setup:
    - sudo apt-get update
    - sudo apt-get install -y htop ffmpeg libsm6 libxext6 git ninja-build libglib2.0-0 libsm6 libxrender-dev libxext6
    - pip install --no-cache-dir --upgrade pip wheel

# environment:
#   image: amlt-sing/acpt-2.2.2-py3.10-cuda12.1
#   # image: amlt-sing/pytorch-1.8.0-cuda11.1-cudnn8-devel
#   # image: amlt-sing/pytorch-2.3.1-cuda11.8-cudnn8-devel
#   # image: amlt-sing/ptca-1.11.0-cuda11.5
#   setup:
#     - sudo apt-get update
#     - sudo apt-get install -y htop ffmpeg libsm6 libxext6 git ninja-build libglib2.0-0 libsm6 libxrender-dev libxext6
#     - pip install --no-cache-dir --upgrade pip wheel

storage:
  input:
    storage_account_name: sanbpx4p3idss6q   # TODO!!
    container_name: v-dingxin  # TODO!!
    mount_dir: /mnt/input/
  # output:
  #   storage_account_name: sanbpx4p3idss6q
  #   container_name: v-dingxin
  #   mount_dir: /home/v-dingxin/blob
  #   is_output: True

code:
  # local directory of the code. this will be uploaded to the server.
  # $CONFIG_DIR is expanded to the directory of this config file
  local_dir: /home/v-dingxin/videollama2_plus-main   #TODO!!

jobs:
  - name: videollm_mamba_stream_zero2_withoutcpu
    sku: 80G8-A100
    command:
    - pip install packaging
    - pip install decord
    - pip install -r requirements.txt
    - pip install flash-attn==2.5.8 --no-build-isolation
    - pip install scikit-image
    - pip install transformers==4.44.2
    - pip install mamba_ssm==2.2.2
    - pip install ftfy regex tqdm Pillow opencv-python timm==0.6.12 einops fvcore
    - pip install moviepy --user
    - pip install scenedetect
    - pip install accelerate -U
    - torchrun --nproc_per_node=8 --node_rank 0 videollama2/train_flash_attn_score.py
        --output_dir /mnt/input/finetune_videollama2_mamba_batch1_newcode_1127_mambaprojector_stream_epoch15_8a100_30
        --deepspeed scripts/zero2.json
        --version v1_mistral
        --score_dataset True
        --vision_tower /mnt/input/clip-vit-large-patch14-336
        --freeze_backbone False
        --mm_projector_type mamba
        --model_name_or_path /mnt/input/VideoLLaMA2-7B
        --data_path  /mnt/input/video_llm/datasets/videollava_pt/valley_llavaimage_new.json
        --data_folder /mnt/input/video_llm/datasets/videollava_pt
        --mm_vision_select_layer -2
        --mm_use_im_start_end False
        --mm_use_im_patch_token False
        --image_aspect_ratio pad
        --num_frames 32
        --bf16 True
        --tf32 True
        --fp16 False
        --num_train_epochs 15
        --per_device_train_batch_size 1
        --per_device_eval_batch_size 4
        --gradient_accumulation_steps 2
        --evaluation_strategy "no"
        --save_strategy "steps"
        --save_steps 50
        --save_total_limit 99
        --learning_rate 2e-5
        --weight_decay 0.
        --warmup_ratio 0.03
        --lr_scheduler_type "cosine"
        --logging_steps 1
        --model_max_length 20480
        --gradient_checkpointing True
        --dataloader_num_workers 8
        --report_to tensorboard
        --run_name videollama2_stp_vllava
    identity: managed
    submit_args:
      env:
        _AZUREML_SINGULARITY_JOB_UAI: /subscriptions/e546c811-2312-46e2-9fd0-c949c65da4d9/resourcegroups/srgx/providers/Microsoft.ManagedIdentity/userAssignedIdentities/srgxuai
    sla_tier: premium
    execution_mode: basic 
    priority: high